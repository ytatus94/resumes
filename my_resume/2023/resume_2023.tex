\documentclass[12pt,a4paper,roman]{moderncv}
% possible options include:
% font size ('10pt', '11pt' and '12pt'), 
% paper size ('a4paper', 'letterpaper', 'a5paper', 'legalpaper', 'executivepaper' and 'landscape')
% font family ('sans' and 'roman')

% modern themes
\moderncvstyle{banking}
% style options are 'casual' (default), 'classic', 'oldstyle' and 'banking'
\moderncvcolor{blue}
% color options 'blue' (default), 'orange', 'green', 'red', 'purple', 'grey' and 'black'
%\renewcommand{\familydefault}{\sfdefault}
% to set the default font; use '\sfdefault' for the default sans serif font, '\rmdefault' for the default roman one, or any tex font name
\nopagenumbers{}
% uncomment to suppress automatic page numbering for CVs longer than one page

% character encoding
\usepackage[utf8]{inputenc}
\usepackage{fontawesome}
\usepackage{fontspec}
\usepackage{tabularx}
\usepackage{ragged2e}
% if you are not using xelatex ou lualatex, replace by the encoding you are using
%\usepackage{CJKutf8}
% if you need to use CJK to typeset your resume in Chinese, Japanese or Korean

% adjust the page margins
\usepackage[scale=0.85]{geometry}
\usepackage{multicol}
%\setlength{\hintscolumnwidth}{3cm}
% if you want to change the width of the column with the dates
%\setlength{\makecvtitlenamewidth}{10cm}
% for the 'classic' style, if you want to force the width allocated to your name and avoid line breaks. be careful though, the length is normally calculated to avoid any overlap with your personal info; use this at your own typographical risks...

\usepackage{import}

% personal data
\name{Dr. Yu-Ting}{Shen}
% \title{Curriculum Vitae}
% \address{}{}{}
% optional, remove / comment the line if not wanted; the "postcode city" and and "country" arguments can be omitted or provided empty
% \phone[mobile]{909-839-3097}
% \phone[fixed]{01234 123456}
% \phone[fax]{+3~(456)~789~012}
% \email{xpan1@swarthmore.edu}
% \homepage{shawnpan.me}
\extrainfo{}
%\photo[64pt][0.4pt]{picture}
% '64pt' is the height the picture must be resized to, 
% 0.4pt is the thickness of the frame around it (put it to 0pt for no frame) and 'picture' is the name of the picture file
%\quote{Some quote}

% to show numerical labels in the bibliography (default is to show no labels); only useful if you make citations in your resume
%\makeatletter
%\renewcommand*{\bibliographyitemlabel}{\@biblabel{\arabic{enumiv}}}
%\makeatother
%\renewcommand*{\bibliographyitemlabel}{[\arabic{enumiv}]}% CONSIDER REPLACING THE ABOVE BY THIS

% bibliography with mutiple entries
%\usepackage{multibib}
%\newcites{book,misc}{{Books},{Others}}
  
% \newcommand*{\customcventry}[7][.25em]{
%   \begin{tabular}{@{}l} 
%     {\bfseries #4}
%   \end{tabular}
%   \hfill% move it to the right
%   \begin{tabular}{l@{}}
%      {\bfseries #5}
%   \end{tabular} \\
%   \begin{tabular}{@{}l} 
%     {\itshape #3}
%   \end{tabular}
%   \hfill% move it to the right
%   \begin{tabular}{l@{}}
%      {\itshape #2}
%   \end{tabular}
%   \ifx&#7&%
%   \else{\\%
%     \begin{minipage}{\maincolumnwidth}%
%       \small#7%
%     \end{minipage}}\fi%
%   \par\addvspace{#1}}

\newcommand*{\customcventry}[7][.25em]{
  {\bfseries #3}\hfill{\bfseries #4}, {\bfseries #5} \hfill {\bfseries #2}
  % \begin{tabular}{@{}l} 
  %   {\bfseries #4}
  % \end{tabular}
  % \hfill% move it to the right
  % \begin{tabular}{l@{}}
  %    {\bfseries #5}
  % \end{tabular} \\
  % \begin{tabular}{@{}l} 
  %   {\itshape #3}
  % \end{tabular}
  % \hfill% move it to the right
  % \begin{tabular}{l@{}}
  %    {\itshape #2}
  % \end{tabular}
  \ifx&#7&%
  \else{\\%
    \begin{minipage}{\maincolumnwidth}%
      \small#7%
    \end{minipage}}\fi%
  \par\addvspace{#1}}

% \newcommand*{\customcvproject}[4][.25em]{
% %   \vfill\noindent
%   \begin{tabular}{@{}l} 
%     {\bfseries #2}
%   \end{tabular}
%   \hfill% move it to the right
%   \begin{tabular}{l@{}}
%      {\itshape #3}
%   \end{tabular}
%   \ifx&#4&%
%   \else{\\%
%     \begin{minipage}{\maincolumnwidth}%
%       \small#4%
%     \end{minipage}}\fi%
%   \par\addvspace{#1}}

% \setlength{\tabcolsep}{12pt}

%----------------------------------------------------------------------------------
%            content
%----------------------------------------------------------------------------------
\begin{document}
%\begin{CJK*}{UTF8}{gbsn}                          % to typeset your resume in Chinese using CJK
%-----       resume       ---------------------------------------------------------
\makecvtitle
\vspace*{-18mm}

\begin{center}
\begin{tabular}{ l l }
 % \faGlobe\enspace 
 \faLinkedinSquare\enspace \href{https://www.linkedin.com/in/yu-ting-shen-6b730b160/}{yu-ting-shen-6b730b160} & \faEnvelopeO\enspace \href{mailto:ytatus94@yahoo.com.tw}{ytshen2020@gmail.com} \\
 \faGithub\enspace \href{https://github.com/ytatus94}{ytatus94} & \faMobile\enspace (405).200.2633\\  
\end{tabular}
\end{center}

% \section{SKILLS}
% {
% \begin{itemize}
%     \item \textbf{Programming}: Python, SQL, C/C++, Spark, Scala, Bash shell script, VBA,
%     \item \textbf{Machine learning, Deep learning, Reinforcement learning}: Scikit-learn, Keras, TensorFlow, PyTorch, Gym, Stable-Baselines, Ray,
%     \item \textbf{Analysis \& Modeling}: ETL, EDA, Predictive modeling, Time series forecast, Anomaly detection, Monte Carlo simulation, RandomForest, XGBoost, LightGBM, LSTM, clustering, %NLP, Recommendation systems, Hypothesis test, A/B test, 
%     \item \textbf{Database}: SQL, Big Query, PostgreSQL, Incorta,
%     \item \textbf{visualization}: Matplotlib, Seaborn, Dash, Bokeh, Google DataStudio, Tableau, Power BI,
%     \item \textbf{Cloud}: Google Cloud Platform, Microsoft Azure, Amazon AWS, Cloudera,
%     \item \textbf{Others}: Git, Docker, Anaconda, Jupyter, Databrick, Visual Studio Code, IntelliJ, Jira, 
%     \item \textbf{Soft skills}: Collaboration, Communication, Problem-solving, Leadership,
% \end{itemize}
% }

\section{EXPERIENCE}

{\customcventry{2019/04 - present}{Senior Data Scientist}{Seeloz Inc}{San Jose, CA}{}
{\begin{itemize}
% \item Developed and maintained a reinforcement learning model using deep-Q learning neural network (DQN) to optimize inventory control and supply chain efficiency for a leading auto parts manufacturer in Malaysia. This model lowered the client's annual total inventory by 26\% from \$7.82M to \$5.77M and increased annual turnover rate by 44\% from 15.42 to 22.27.
% \item Utilized SQL, Python, and Spark to analyze supply chain data and developed ensemble models using ETS, ARIMA, RandomForest, XGboost, and LSTM for time series forecasting. Achieved model accuracy ranging from 83\% to 97\% across products and boosted coverage of products by 10 times
% \item Designed a novel approach for tackling non-convergence issues in sparse time series data by leveraging a double random forest model with postponed action and accomplished a 68\% reduction in MAE.
% \item Developed an anomaly detection model to uncover 3-5\% anomalies in customers' ordering. Utilized this model in data engineering to improve accuracy by 9.8\% in a time series forecasting model.
% \item Developed multi echelon single product reinforcement learning model for the world's largest oil company to optimize its oil transportation scheduling plan, reduce inventory costs, and fulfill customer demands more efficiently.
% \item Developed a Python-based API that offers cross-platform capabilities for accessing cloud storage on GCP, Azure, and AWS. The API was adopted in all Seeloz products and significantly enhanced workflows’ efficiency and functionality.
% \item Created dynamic dashboards with Google DataStudio and Python Dash package, enhancing accessibility and usability of critical data insights for stakeholders.
% \item Designed a Python-based universal interface to submit batch jobs to Google AI platform, GKE, Azure VMSS, Azure ML, AKS, on-premises cluster, and local docker container.
% \item Collaborated cross-functionally to design and implement sophisticated analytical solutions at scale, delivered high-quality outcomes that exceeded project requirements and met stakeholder needs.
% \item Led junior data scientists on the team and facilitated resolution of project-related challenges.
%%%%
% \item Analyzed clients' supply chain raw data using Python and SQL to create data ETL using PySpark.
% \item Developed the data schema and table architecture for SCAS metadata model using the raw data from Oracle ERP.
% \item Implemented a reinforcement learning model to optimize supply chain management and inventory control. Lowered annual inventory by 26\% and increased annual turnover rate by 44\%.
% \item Built time series forcasting model using ETS, ARIMA and Random Forest and achieved model accuracy from 83\% to 97\% across products.
% \item Created interactive dashboard using Python Dash and deployed on Azure using Docker. Experienced and proficient in Tableau, Power BI, Google DataStudio to visualize and analyze data.
% \item Developed a Python API offering cross-platform capabilities for accessing storage blobs on GCP, Azure, and AWS.
% \item Developed a Sell script for submitting model training jobs to Google AI platform, Azure VMSS, and on-premises cluster.
% \item Led Junior data scientists on the team and facilitated resolution of project-related challenges
%%%%
\item Analyzed large supply chain datasets using \textbf{SQL} and \textbf{BigQuery} to identify root causes of business inefficiencies and performed data cleaning and ETL using \textbf{Python} and \textbf{Pandas}
\item Generated data visualizations and prepared analytical reports using \textbf{Jupyter}, \textbf{Matplotlib}, \textbf{Seaborn}, and \textbf{Plotly} packages which improved data visibility and supply chain understanding 
% show impact on the customer and products and numbers, how does this help?
\item Built predictive models for demand forecasting using \textbf{Scikit-Learn}, \textbf{XGBoost}, \textbf{LightGBM}, and \textbf{TensorFlow} and achieved $r^2=0.92$ which facilitated operational planning
% \item Trained time series forecasting models using a novel method with double random forest and achieve excess XXXXX accuracy.
% \item Trained time series forecasting models using \textbf{ETS}, \textbf{ARIMA}, \textbf{Exponential-Smoothing} and \textbf{Prophet}
% \item Built \textbf{anomaly detection} models to detect anomaly in orders and deliveries in supply chain --> what is the impact or achievement?
\item Implemented \textbf{Reinforcement Learning} models to automate supply chain procurement and reduce cost by $\sim$30\% through inventory level and stock outs optimization
%
\item Automated machine learning training and inference workloads with Linux Shell and \textbf{Docker} using cloud platforms such as Azure ML Studio, Google AI Platform
\item Developed internal Python libraries to facilitate data ETL across cloud and on-prem platforms such as \textbf{GCP}, \textbf{Azure}, \textbf{AWS} which improved developer efficiency by 3x and minimized security risks
\item Created dashboards using \textbf{Google Data Studio}, \textbf{Tableau} and \textbf{Power BI} in collaboration with engineering, product, and executive teams which show supply chain metrics for stakeholders to help decision making
\item Implemented industry standard procurement models including \textbf{EOQ}, \textbf{TPOP}, and \textbf{ROP} to compare and contrast behavior with trained AI models and reduced model evaluation time by 2x
% \item Developed Shell script to submit training jobs to \textbf{Google AI platform}, \textbf{Azure VMSS} and \textbf{on-premises} clusters.
% \item Led junior data scientists on the team and facilitated resolution of project-related challenges.
%%%
% \item Analyzed supply chain data from ERP system using \textbf{SQL} and \textbf{Python}, and create data ETL pipeline using \textbf{PySpark}.
% \item Visualized supply chain trends and inefficiencies using \textbf{Matplotlib}, \textbf{Seaborn}, \textbf{Bokeh}, and \textbf{Plotly}.
% \item Created interactive dashboards using Python \textbf{Dash} and deployed on \textbf{Azure} using \textbf{Docker}. Experienced and proficient in \textbf{Tableau}, \textbf{Google DataStudio}, and \textbf{Power BI}.
% \item Implemented \textbf{Reinforcement Learning} models to optimize supply chain management and inventory control. Lowered annual inventory by 26\% and increased annual turnover rate by 44\%.
% \item Built \textbf{anomaly detection} models for customers' orders and found 3\% $\sim$ 5\% anomaly across products.
% \item Built \textbf{predictive models} to forecast customer's demand using ETS, ARIMA, Exponential-Smoothing (\textbf{statsmodels}), and \textbf{Prophet}. Achieved model accuracy ranging from 83\% to 97\% across products.
% \item Improved 3\% $\sim$ 17\% accuracy in \textbf{time series forecasting} model results for different products by using RandomForest (\textbf{scikit-learn}), \textbf{XGBoost}, \textbf{LightGBM}, and LSTM (\textbf{TensorFlow}).
% \item Developed a Python API offering cross-platform capabilities for accessing storage blobs on \textbf{GCP}, \textbf{Azure}, and \textbf{AWS}.
% \item Developed a \textbf{Bash shell script} for submitting model training jobs to Google AI platform, Azure VMSS, and on-premises cluster.
%%%
\end{itemize}
}
% \item Analyzed customers' supply chain data using SQL/Python/Spark and built ensemble models for time series forecasting using ETS/ARIMA/RandomForest/XGboost/LSTM. The model accuracy ranges from 93\% to 100\% for various products for different customers.
% \item Built interactive dashboards for visualizations and quick inspections. The dashboards were constructed on the Google DataStudio at the beginning, and then ported to Python with Bokeh package now.
% \item Built interactive dashboards for visualizations using Google DataStudio and Python Dash package. The dashboards not only visualize data but also summarize key metrics, present prediction results and analytical outcomes. 
% \item Developed and implemented a NLP model utilizing data from Bill of Materials (BOM) and Product tables to categorize product types and achieving accuracy 98\%.

%\item Reduced the inventory levels 30\% $\sim$ 70\%, which varies by warehouses and products, and retained low stock-outs by introducing the purchase-procurement splitting and postponed action methods into the model-based reinforcement learning (RL).
% \item Applied the time series analysis and forecasting methods using Python and predicted customers' demands and orders. The models been used including ETS, ARIMA/SARIMA, VAR, long-short term memory (LSTM), and double random forest (double RF). The $r^2$ score was improved from 0.15 (using ETS model) up to 0.92 (using double RF) and the number of supported products have been increased by a factor of 20 times.
% \item Migrated the AP\&I platform from Stable-Baselines to Ray.
% \item Analyzed supply chain data from various clients by writing SQL queries on the Google Big Query and PostgreSQL. 
% \item Implemented an abstraction layer (API), called Cloud I/O, on top of Azure and GCP to access the Azure storage account and Google Cloud storage. This Python-based API provides the AP\&I cross-platform functionalities.
% \item Designed a Python-based universal interface to submit batch jobs to Google AI platform, GKE, Azure VMSS, Azure ML, AKS, on-premises cluster, and local docker container.
% \item Implemented an abstraction layer (API) on top of 3 major cloud platforms (GCP, Azure, and AWS) to access the cloud storage. This Python-based API provides the AP\&I cross-platform functionalities.
% \item Time series forecasting to forecast customers' demand, ordering, purchase-procurement splitting with the X\% accuracy for different products and customers.
% \item Built new LSTM models using Keras for demands and orders time series data predictions and improved the $r^2$ score from 0.15 to 0.94.
% \item Designed an API to access the Google Cloud Storage and Microsoft Azure Storage accounts. Using this API, the users can switch between cloud service providers without modifying their code base.
% \item Established and conducted the data processing pipeline to extract useful information from large dataset, integrated the results into Incorta database and updated the SQL queries in the dashboard.
% \item Helped customers to reduce the costs and lost sales by performing anomaly detection and data visualization to find out the unusual distributions of inventory and procurement in customers' datasets.
% \item Managed and upgraded the Cloudera making Spark and jupyter service run over all the Seeloz Clusters.
% \item Suggest and explore novel solutions to data science/data visualization/data pipeline problems.
% \item Built a time-series model for a seasonal product category to test, compare and validate supply chain team’s predictions.
% \item Prepared structural databases to build complex data frames for team usage and provided complex business analytics, measures, visuals and insights from raw data for assortment planning management to make knowledgeable and data-driven decisions.
% \item Designed machine learning and predictive models to test and verify the store market area definitions to the rolling-12 month collected data. This project involved data modeling and machine learning algorithm (training, testing and scoring) implementation using various predictive algorithms such as decision trees, random forest, etc.
% \item Led ML projects in reinforcement learning and time series forecasting to deliver real time models. Led visualization project to ship interactive dashboards. Led engineer project to develop universal API for accessing cloud storage from different cloud platforms.
% \item Worked cross-functionally with product managers, data engineers, and data architects, to design and deliver large-scale advanced analytic solutions
%\item Collaborated seamlessly with cross-functional teams, including product managers, data engineers, and data architects, to design and implement sophisticated analytical solutions at scale. By leveraging diverse perspectives and expertise, successfully delivered high-quality outcomes that exceeded project requirements and met the needs of stakeholders across the organization.
% \item Developed and maintained reinforcement learning (RL) based framework using deep-Q learning (DQN) for single and multiple echelons to optimize the profitability and minimize supply chain inefficiencies. The annual total inventory values are reduced from \$7.82M to \$5.77M (26\% lower) and the annual turnover rate is increased 44\% from 15.42 to 22.27. %Help the customers to safe Y\% of the cost and earn Z\% revenues.
% \item Developed and maintained the essential deep-Q learning network (DQN) models in SCAS Autonomous Procurement \& Inventory (AP\&I) platform to optimize profitability and minimize supply chain inefficiencies. The annual total inventory values are reduced from \$7.82M to \$5.77M (26\% lower) and the annual turnover rate is increased 44\% from 15.42 to 22.27.
% \item Developed and maintained the essential deep-Q learning network (DQN) models for inventory control to optimize profitability and minimize supply chain inefficiencies. The annual total inventory values are reduced from \$7.82M to \$5.77M (26\% lower) and the annual turnover rate is increased 44\% from 15.42 to 22.27.
%\item Developed and deployed a deep-Q learning neural network (DQN) in reinforcement learning, which optimizes the supply chain management, and provides recommendations to customers. This DQN model helps customers saving \$2.05M in the inventory costs and increasing 44\% annual turnover rate.



% {\customcventry{2018/07 - 2019/01}{Postdoctoral Researcher}{University of Oklahoma \& Louisiana Tech University}{Norman, OK}{}
% {\begin{itemize}
%   \item I do something awesome
% \item Investigated 1M+ new experimental records to improve model prediction precision by uncovering the hidden relation between momentum and TPR.
% \item Generated Monte Carlo simulation data and extracted useful features by applying feature engineering.
% \item Builted decision tree model and use simulated data to train model.
% % FOR RESUME & CV
% \item 6 semesters teaching assistant for college and graduate level courses.
% \item Been teaching assistant and helped professors to grade homework, proctor exams, and compile student achievement statistics for many courses.
% \item Stationed at CERN and dedicated to search for supersymmertic particles since 2015.
% \item Relocated to CERN since 2015. Analyzed large experimental datasets to search for supersymmertic particles among other duties.
% \end{itemize}
% }

{\customcventry{2015/03 - 2018/03}{Data Scientist}{CERN}{Geneva, Switzerland}{}
% {\customcventry{2015/03 - 2018/03}{Data Scientist}{CERN (Organisation Europ\'{e}enne pour la Recherche Nucl\'{e}aire )}{Geneva, Switzerland}{}
{\begin{itemize}
  % \item Improved the electron isolation efficiency from 83\% to 99\% (a 19\% increase) by restricting the transverse energy and momentum distributions within a topological cone of 0.2 in spherical coordinate. The outcome set a new benchmark for all analysis at CERN.
  \item Designed, optimized, and implemented a high-performing \textbf{classification model} for real leptons across multiple energy scales, leveraging both statistical and machine learning methodologies which increased the model's recall from 62\% to 98\%
  \item Improved electron isolation efficiency from 83\% to 99\% (a 19\% increase) which set a new benchmark for all analysis at CERN
  \item Conducted a comprehensive analysis of an extensive 400 TB dataset and employed \textbf{decision tree}, \textbf{multi-dimensional regression}, and \textbf{statistical models} to deliver sophisticated solutions that effectively addressed complex project requirements
\end{itemize}
}

{\customcventry{2009/07 - 2011/07}{Research Scientist}{Academia Sinica}{Taipei, Taiwan}{}
{\begin{itemize}
  \item Created a \textbf{Monte Carlo simulation} model using \textbf{C++} which increased 20\% precision
  % \item Developed decision tree and boosted ensemble models using C++ and ROOT, and applied 3-fold cross-validation to enhance particle classification accuracy by approximately 10\%.
  % \item Led cross-functional collaboration between different departments to establish remote control capabilities for experiments.
\end{itemize}
}
% \item Discovered serious bugs in simulation programs by performing exploratory data analysis on simulated data.
% \item Programmed in C++ to redesign a bug-free Monte Carlo simulation programs.
% \item Improved 50\% of the signal significance by devising a new classification model.
% \item Performed exploratory data analysis on simulated data and discovered serious bugs in simulation programs.
% \item Discovered serious bugs and redesigned Monte Carlo simulation programs using C++ to improve the accuracy.
% \item Devised a new classification model to improve the accuracy of signal and background identification.
% \item Devised a new classification model by implementing decision tree algorithm.
% \item Used machine learning model to improve the accuracy of signal and background identification and reduced the major background events by 50\%.
% \item Used decision tree based methods to classify background sources and reduced the major background events by 50\%.
% \item Classified different background using decision tree based methods, automated the analysis results visualization processes, and reported the finding.

{\customcventry{2006/12 - 2009/02}{R\&D Engineer}{TSMC}{Hsinchu, Taiwan}{}
% {\customcventry{2006/12 - 2009/02}{R\&D Engineer}{TSMC (Taiwan Semiconductor Manufacturing Company)}{Hsinchu, Taiwan}{}
{\begin{itemize}
  \item Performed rigorous \textbf{statistical analysis} to develop device models for advanced IC devices with cutting-edge technology relating to semiconductor process nodes
  % \item Achieved a 40\% improvement in performance by designing and deploying an ETL and analysis pipeline on-premises.
  % \item Managed 7 projects by defining project scopes, allocating resources, scheduling and monitoring project progress, and coordinating cross-functional teams to ensure timely and high-quality project delivery.
\end{itemize}
}
% \item Developed C/C++ programs for the measurement system to automate raw data collection processes which results in 1.5$\times$ $\sim$ 3$\times$ speed improvements depending on the scope of measurements.
%clean the measured raw data, apply feature engineering to extract significant features for modeling, build clustering and multi-dimentional regression models for various device types, utilize statistical models to finalize device parameters in the 95\% confidence interval, validate model performance by running MC simulation and build confusion matrix, and visualize the Id-Vg and Id-Vd distributions.
% \item Led and managed 7 projects to coordinate effectively with the cross-functional teams and clients, defined the project specifications (SPEC) and schedules, created standard operating procedures (SOP) for various analysis steps, documented the usages and performances of all device models in the project SPEC for the clients.
% \item Developed C/C++ based programs for the measurement system to automate raw data collection processes which reduces manual-operation time from 3 $\sim$ 6 hours to 2 $\sim$ 4 hours depending on the scope of measurements. This results in 30\% to 60\% improvements of the raw data collection performance.
% \item Programmed measurement system to automate data collection processes and reduced 30\% of manual-operation time.
% \item Implemented regression algorithm for data fitting and validated model with advanced statistical method.
% \item Implemented regression algorithm to fit data and applied statistics on the measured data to validate the regression model.
% \item Developed a standard operating procedure (SOP) in analysis pipeline to reduced 5\% to 10\% model variance and instructed colleagues how to apply the SOP in their projects.
% \item Converted potential clients to paying clients by providing preliminary models matching clients' specifications.
% \item Led and supported 7 projects to build various models to predict the device performances and documented the model usages and performances.
% \item Led and supported 7 projects of various device models and built model performance documents for clients.
% \item Led and supported 7 projects to build device models using regression, visualized and documented the results for customers.
% \item Led and supported 7 projects to build device models and documented the results for customers.
% \item Led and supported 7 projects, performed model parameterization, validation, visualization, documentation, and provided customer support.
% \item Built analysis pipeline to clean and visualize data.
%\item Coordinated effectively with cross-functional teams and clients to resolve issues with tight deadlines.
% \item Completed an urgent project 2 months ahead of the normal schedule and saved the contract.

\section{SKILLS}
{
\begin{itemize}
    \item \textbf{Programming}: Python, SQL, C/C++, Spark, Bash shell
    \item \textbf{Machine learning, Deep learning}: Scikit-learn, Keras, TensorFlow, PyTorch
    \item \textbf{Reinforcement learning}: Gym, Stable-Baselines, Ray
    % \item \textbf{Analysis \& Modeling}: ETL, EDA, Predictive modeling, Time series forecast, Anomaly detection, Monte Carlo simulation, RandomForest, XGBoost, LightGBM, LSTM, clustering, %NLP, Recommendation systems, Hypothesis test, A/B test, 
    % \item \textbf{Database}: SQL, Big Query
    \item \textbf{Visualization}: Matplotlib, Seaborn, Dash, Bokeh, Google DataStudio, Tableau, Power BI
    \item \textbf{Cloud}: Google Cloud Platform, Microsoft Azure
    \item \textbf{Others}: Git, Docker, Jupyter, Databrick, Visual Studio Code, Jira
    \item \textbf{Soft skills}: Collaboration, Communication, Problem-solving, Leadership
\end{itemize}
}

\section{EDUCATION}
{\customcventry{2011 - 2018}{Ph.D. in Physics}{University of Oklahoma}{Norman, OK}{}{}}
% {\customcventry{2003 - 2006}{M.S. in Physics}{National Taiwan University}{Taipei, Taiwan}{}{}}
% {\customcventry{1998 - 2002}{B.S. in Physics}{Chung Yuan Christian University}{Chung Li, Taiwan}{}{}}
\end{document}


% \section{PROJECTS}

% {\customcvproject{Amazing Project 1}{Aug 2017 - Present}
%   {\begin{itemize}
%     \item Ran custom Minecraft mods on CentOS and Debian servers
%     \item Reverse engineered obfuscated Java using a decompiler and reflection
%   \end{itemize}
%   }
% }

% {\customcvproject{Amazing Project 2}{Feb 2016 – May 2017}
% {\begin{itemize}
%   \item Began a group to create the first 36 hour student-run hackathon ever held at Illinois
%   \item Led 50 staff to raise \$175,000 for HackIllinois, managing relationships with 60+ sponsors
%   \item Plan events to increase social interaction among ACM members, as well as events to foster the spirit of computer science at Illinois
% \end{itemize}
% }

% {\customcvproject{Amazing Project 3}{Jan 2015 – May 2015}
% {\begin{itemize}
%   \item Assist in recruiting potential and admitted students to the UIUC computer science program
%   \item Attend information sessions, admitted student Q\&A’s, and student lunches to generate interest in the Illinois Computer Science department
% \end{itemize}
% }
% }

% \section{ADDITIONAL}
% \begin{minipage}{\maincolumnwidth}%
% 	\small{
%     	\begin{itemize}
%           \item Relevant Coursework: Data Structures and Algorithms, Natural Language Processing, Computer Systems, Databases, Computer Security, Abstract Algebra
%           \item President of XYZ Club, Public Relations Manager of Swarthmore QWE Club
%           \item Programming Languages: Python, C, C++, PHP, Java, HTML/CSS, Javascript, jQuery, NodeJS
%           \item Fluent in Gibberish, conversational in Nonsense
% 		\end{itemize}}%
% \end{minipage}%
      
% }
% Publications from a BibTeX file without multibib
%  for numerical labels: \renewcommand{\bibliographyitemlabel}{\@biblabel{\arabic{enumiv}}}% CONSIDER MERGING WITH PREAMBLE PART
%  to redefine the heading string ("Publications"): \renewcommand{\refname}{Articles}
% \nocite{*}
% \bibliographystyle{plain}
% \bibliography{publications}                        % 'publications' is the name of a BibTeX file

% Publications from a BibTeX file using the multibib package
%\section{Publications}
%\nocitebook{book1,book2}
%\bibliographystylebook{plain}
%\bibliographybook{publications}                   % 'publications' is the name of a BibTeX file
%\nocitemisc{misc1,misc2,misc3}
%\bibliographystylemisc{plain}
%\bibliographymisc{publications}                   % 'publications' is the name of a BibTeX file

%-----       letter       ---------------------------------------------------------




%% end of file `template.tex'.
